{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":793542,"sourceType":"datasetVersion","datasetId":355}],"dockerImageVersionId":30260,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 2. Data reading and Cleaning","metadata":{}},{"cell_type":"code","source":"#import librarys\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns \nimport dataframe_image as dfi\nfrom functools import reduce #\nfrom datetime import datetime, timedelta\nfrom scipy.stats import chi2_contingency\nfrom functools import reduce #import reduce from functools\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#read data\nairports = pd.read_csv(\"airports.csv\") #airport variables\ncarriers = pd.read_csv(\"carriers.csv\") #carrier variables\nairplanes = pd.read_csv(\"plane-data.csv\") #airplane variables\n\ndf1 = pd.read_csv(\"2006.csv\") #import data for year 2006\ndf2 = pd.read_csv(\"2007.csv\") #import data for year 2007\ndf3 = pd.read_csv(\"2008.csv\") #import data for year 2008","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#see and compare data shape\nprint(df1.shape) #year 2006\nprint(df2.shape) #year 2007\nprint(df3.shape) #year 2008","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check for missing datapoints in 2008.csv (due to the small size compared to other years)\ndf3['Month'].value_counts() ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#year 2008 only has month up to april, so we don't use it.\n\n#check for NA's for 2006 and 2007\nprint(df1.isna().sum())\nprint(df2.isna().sum())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If we adress NA's now, i it could potentially lead to loss of important datapoints. Let's instead try to see if there is a rational explanation for some of theese, i.e. if a flight is cancelled, then any delay entry shouldn't be possible. ","metadata":{}},{"cell_type":"code","source":"#check for correlation between cancellation and delays \n\n#merge dataframes for 2006 and 2007\ncancel_org = pd.concat([df1, df2],ignore_index=True) #we can also use to verify NA's later.\n\n#select columns of interest\ncancel=cancel_org[['Cancelled','CancellationCode','ArrDelay','DepDelay','CarrierDelay','WeatherDelay','NASDelay','SecurityDelay','LateAircraftDelay']]\n\n#correlation heatmap (check how cancelations are correlated to delays)\ncancel_heatm = sns.heatmap(cancel.corr()) #plot the heatmap\ncancel_heatm\n#cancel_heatm.figure.savefig(\"clean_plot1.png\") #save to img","metadata":{"execution":{"iopub.status.busy":"2024-06-10T12:23:46.359078Z","iopub.execute_input":"2024-06-10T12:23:46.359613Z","iopub.status.idle":"2024-06-10T12:23:46.453600Z","shell.execute_reply.started":"2024-06-10T12:23:46.359505Z","shell.execute_reply":"2024-06-10T12:23:46.451883Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/4098862906.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#merge dataframes for 2006 and 2007\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcancel_org\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#we can also use to verify NA's later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#select columns of interest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"],"ename":"NameError","evalue":"name 'pd' is not defined","output_type":"error"}]},{"cell_type":"code","source":"#the heatmap suggest a very strong correlation\n\n#narrow in on the issue\ncancel2 = cancel[['Cancelled','CancellationCode','ArrDelay','DepDelay']]\ncancel2=cancel2[cancel2['Cancelled']==1] #  select only cancelled flights\n\n#explore cancelation data\nprint(cancel2)\nprint(cancel2.isna().sum()) #sum of NA's","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dataframes without cancelled flights.\ndf1=df1[df1['Cancelled']==0] \ndf2=df2[df2['Cancelled']==0] \n\n#Similarly if a plane is diverted, then arrival delay entry should be impossible.\n#remaining NA values corresponds to diverted in the same way as cancelled.\nprint(df1.ArrDelay.isna().sum()) #sum of NA's\nprint(df1.DepDelay.isna().sum()) #sum of NA's\nprint(df2.ArrDelay.isna().sum()) #sum of NA's\nprint(df2.DepDelay.isna().sum()) #sum of NA's","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#heatmap of correlation between diverted and delays\n\n#columns of interest\ndiverted=cancel_org[['Diverted','CancellationCode','ArrDelay','DepDelay','CarrierDelay','WeatherDelay','NASDelay','SecurityDelay','LateAircraftDelay']]\n\n#correlation heatmap\ndiverted_heatm = sns.heatmap(diverted.corr()) #plot the heatmap\ndiverted_heatm\n#diverted_heatm.figure.savefig(\"clean_plot2.png\") #save to img","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#again we see a very strong correlation. so we select non-diverted flights.\n\n#dataframes without diverted flights.\ndf1=df1[df1['Diverted']==0] \ndf2=df2[df2['Diverted']==0] \n\n#if our assumption regarding diverted is true, NA's should excluded from ArrDelay and DepDelay\nprint(df1.ArrDelay.isna().sum()) #sum of NA's\nprint(df1.DepDelay.isna().sum()) #sum of NA's\nprint(df2.DepDelay.isna().sum()) #sum of NA's\nprint(df2.ArrDelay.isna().sum()) #sum of NA's","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#see shape of data\nprint(df1.shape)\nprint(df2.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#to avoid any potential bias towards one year, we take sample to match datapoints\ndf2 = df2.sample(7003802)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#merge data (exclude 2008 to avoid bias towards the first 4 months)\ndf = pd.concat([df1, df2],ignore_index=True)\n\n#verify that missing values in cancelled is taken care of\nprint(df['Cancelled'].sum())\n\n#test against original data\nprint(cancel_org['Cancelled'].sum())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#explore the data\ndf ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#merge df with carrier variables to get names of airlines\ndf = pd.merge(df, carriers,  how='inner', left_on=['UniqueCarrier'], right_on = ['Code'])\n\n#rename Description column to Carrier\ndf.rename(columns={'Description': 'Carrier'}, inplace=True)\n\n#create columns\ndf['delay'] = ((df['DepDelay'])+(df['ArrDelay'])) #total delay column for a flight (Departure + Arrival delay)\ndf['dep_hour_standard'] = df['DepTime']/100*1.0386100 #departure standard time column\ndf['Date']= pd.to_datetime(pd.DataFrame({'year':df['Year'],\n                                         'month':df['Month'],'day':df['DayofMonth'], \n                                         'hour':df['dep_hour_standard']})) #date column\n\ndf['dep_hour_int'] = (df['DepTime']/100).astype(int) #departure time column (in integer)\ndf['Date_bin']= pd.to_datetime(pd.DataFrame({'year':df['Year'],\n                                             'month':df['Month'],'day':df['DayofMonth'], \n                                             'hour':df['dep_hour_int']})) #date column in bins\n\ndf.head() #explore new columns","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. EDA","metadata":{}},{"cell_type":"code","source":"#details of delay related columns\ndel_info = df[['ArrDelay','DepDelay','CarrierDelay','WeatherDelay','NASDelay','SecurityDelay',\n               'LateAircraftDelay','delay']] #select columns\ndel_info.rename(columns={'ArrDelay': 'Arrival delay', 'DepDelay': 'Departure Delay',\n                         'CarrierDelay':'Carrier Delay','WeatherDelay':'Weather Delay',\n                         'NASDelay': 'NAS Delay', 'SecurityDelay': 'Security Delay',\n                         'LateAircraftDelay':'Late Aircraft Delay',\n                         'delay':'Total Delay'}, inplace=True) #rename columns\ndel_info = del_info.describe().T #describe and transpose delay information\n\n#export to image \ndel_info_style = del_info.style.format(\"{:.12}\").background_gradient() #style table\ndfi.export(del_info_style,\"EDA_table1.png\") #export to img\ndel_info_style","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#explore departure delays (i.e. outlier, etc.)\nprint(df[\"DepDelay\"][(df[\"DepDelay\"] <0)].count())\nprint(df[\"DepDelay\"][(df[\"DepDelay\"] < -1000)].count())\nprint(df[\"DepDelay\"][(df[\"DepDelay\"] >2000)].count())\n\n#explore arrival delays\nprint(df[\"ArrDelay\"][(df[\"ArrDelay\"] <0)].count())\nprint(df[\"ArrDelay\"][(df[\"ArrDelay\"] < -400)].count())\nprint(df[\"ArrDelay\"][(df[\"ArrDelay\"] >2000)].count())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#explore departure and arrival max outliers\nexp_del = df[['Carrier','TailNum','DepDelay','ArrDelay']]\nexp_del = exp_del[(exp_del[\"ArrDelay\"] >2000) & (exp_del[\"DepDelay\"] >2000)]\n\n#export outlier table\nexp_del_style = exp_del.style.format(\"{:.12}\").background_gradient() #style table\ndfi.export(exp_del_style,\"EDA_table1_2.png\") #export to img\nexp_del_style ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Percentage of all delays\n","metadata":{}},{"cell_type":"code","source":"#total no. of flights ontime, and delayed\ndelay_perc = (df['delay']<=0) #true: before or ontime, false: delayed\ndelay_perc.value_counts() #count","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#manual math cell: percentage of delayed flights\ntot_flights = (6534546+7473058)\ndel_flights = 6534546\nont_flights = 7473058\nperc=del_flights/tot_flights\nperc2=ont_flights/tot_flights\nprint(\"Percentage of flights that are delayed: {:.00%}\".format(perc))\nprint(\"Percentage of flights that are ontime: {:.00%}\".format(perc2))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#change the total delay threshold to 10 minutes:\ndelay_perc2 = (df['delay']<=10) #10 min delay or less.\ndelay_perc2.value_counts() #count","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#manual math cell: percentage of delayed flights (10min  threshold)\ntot_flights = (4671113+9336491)\ndel_flights = 4671113\nont_flights = 9336491\nperc=del_flights/tot_flights\nperc2=ont_flights/tot_flights\nprint(\"Percentage of flights that are delayed: {:.00%} - (10min threshold)\".format(perc))\nprint(\"Percentage of flights that are ontime: {:.00%} - (10min threshold)\".format(perc2))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#set plotting style for notebook\nsns.reset_orig()\nplt.style.use('seaborn-colorblind')\nsns.set_style(\"whitegrid\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot delays\n\n#data prep for plot\n#percentage of delays converted to true/false values\ndelay_perc_plot = pd.DataFrame() #empty df\ndelay_perc_plot['Status']=df['delay']<=0 #column with delay status\nfor col in delay_perc_plot.columns[delay_perc_plot.dtypes == 'bool']:\n    delay_perc_plot['Status'] = delay_perc_plot['Status'].map({True: 'On time', False: 'Delayed'}) #convert to boolean\n\n#percentage of delays with a 10 min threshold (true/false)\ndelay_perc_plot_10 = pd.DataFrame() #cempty df\ndelay_perc_plot_10['Status_10min_int']=df['delay']<10 #10min threshold\nfor col in delay_perc_plot_10.columns[delay_perc_plot_10.dtypes == 'bool']:\n    delay_perc_plot_10['Status_10min_int'] = delay_perc_plot_10['Status_10min_int'].map({True: 'On time', False: 'Delayed'}) #convert to boolean\n\n\n#combined plot\nf, ax = plt.subplots(1,2,figsize=(15, 7))\n\npalette=['C2','C0'] #set colour\n\n(delay_perc_plot['Status'].value_counts(normalize=True)*100).sort_values().plot(kind = 'bar', ax=ax[0], color=palette) #plot in percentage\n(delay_perc_plot_10['Status_10min_int'].value_counts(normalize=True)*100).sort_values().plot(kind = 'bar', ax=ax[1], color=palette) #plot in percentage\n#set labels\nax[0].set_title(\"Percentage of flights: delay vs. on time\",fontsize = 16) #title ax0\nplt.setp(ax[0].get_xticklabels(), rotation=45, ha='right',fontsize = 12) #rotate ax0\nax[0].set(ylabel=\"Percentage\")\nax[1].set_title(\"Percentage of flights: delay vs. on time (10min theshold)\",fontsize = 16) #title ax1\nplt.setp(ax[1].get_xticklabels(), rotation=45, ha='right',fontsize = 12) #rotate ax1\nax[1].set(ylabel=\"Percentage\")\nplt.tight_layout() #tight layout\nplt.style.use('seaborn-colorblind')\nplt.show() #plot","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot delays (total)\n\n#data prep for plot\n#total delay converted to true/false values\ndelay_tot_plot = pd.DataFrame() #empty df\ndelay_tot_plot['Status']=df['delay']<=0 #0 min threshold\nfor col in delay_tot_plot.columns[delay_tot_plot.dtypes == 'bool']:\n    delay_tot_plot['Status'] = delay_tot_plot['Status'].map({True: 'On time', False: 'Delayed'}) #convert to boolean\n\n#total delay 10min threshold\ndelay_tot_plot_10 = pd.DataFrame() #empty df\ndelay_tot_plot_10['Status_10min_int']=df['delay']<10 #10 min threshold\nfor col in delay_tot_plot_10.columns[delay_tot_plot_10.dtypes == 'bool']:\n    delay_tot_plot_10['Status_10min_int'] = delay_tot_plot_10['Status_10min_int'].map({True: 'On time', False: 'Delayed'})\n\n#plot of total delays\nf, ax = plt.subplots(1,2,figsize=(15, 7))\n\npalette=['C2','C0'] #color\n\n(delay_tot_plot['Status'].value_counts()).sort_values().plot(kind = 'bar', ax=ax[0], color=palette)\n(delay_tot_plot_10['Status_10min_int'].value_counts()).sort_values().plot(kind = 'bar', ax=ax[1], color=palette)\n\n#set labels\nax[0].set_title(\"Total no. of flights: delay vs. ontime\",fontsize = 16) #title ax0\nplt.setp(ax[0].get_xticklabels(), rotation=45, ha='right',fontsize = 12) #rotate ax0\nax[1].set_title(\"Total no. of flights: vs. ontime (10min theshold)\",fontsize = 16) #title ax1\nplt.setp(ax[1].get_xticklabels(), rotation=45, ha='right',fontsize = 12) #rotate ax1\nplt.setp(ax, ylabel=\"Total no. in 00000's\") #common y label.\nplt.tight_layout() #tight layout\nplt.show() #plot","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#value count of both delay df's\nprint(delay_tot_plot.value_counts())\nprint(delay_tot_plot_10.value_counts())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#merge and prettify the plots above\n\n#plot data preparation\ndelay_dec_data=[7.473081,6.534523] #totals divided with 1000: fit plot to graph\ndelay_dec = pd.Series(index = [\"On time\", \"Delayed\"], data=delay_dec_data) #create series\npercentage = delay_dec.div(delay_dec.sum()).mul(100).round(2) #calc. the percentage\n\n#barplot with total and percentage in a combined plot (0 min threshold)\nax = delay_dec.plot(kind=\"bar\", alpha=0.7, figsize=(10, 8), color=palette)\n\n#set labels inside the bars\nlabels = [f'{delay_dec} - {percentage[delay_dec]}%' for delay_dec in delay_dec.index]\nfor label, a in zip(labels, ax.patches):\n    left, bottom, width, height = a.get_bbox().bounds\n    ax.annotate(label, xy=(left+width/2, bottom+height/2), ha='center', va='center', rotation=90, fontsize=28)\n#labels\nplt.ylabel(\"Count (mio.)\", fontsize=25) #ylabel\nplt.xlabel(\"Status\", fontsize=25) #xlabel\nplt.title(\"Delay vs. On time\", fontsize=30, fontname=\"Monospace\", alpha=.8) #title\nplt.xticks([]) #empty xticks\nplt.tight_layout(rect=[0, 0, 1, 1]) #tight layout (rectangular)\nplt.savefig('EDA_plot1.png', bbox_inches='tight') #save img\nplt.show()\n\n#barplot with total and percentange in combined plot (10 min threshold)\ndelay_dec_data2=[9.190188,4.817416] #totals divided with 1000: to fit plot to graph\ndelay_dec2 = pd.Series(index = [\"On time\", \"Delayed\"], data=delay_dec_data2) #series\npercentage2 = delay_dec2.div(delay_dec.sum()).mul(100).round(2) #calculate percent\n\n#plot pretty bar for 10min threshold\nax = delay_dec2.plot(kind=\"bar\",  alpha=0.7, figsize=(10, 8), color=palette)\n\n#bar labels\nlabels = [f'{delay_dec2} - {percentage2[delay_dec2]}%' for delay_dec2 in delay_dec2.index]\nfor label, a in zip(labels, ax.patches):\n    left, bottom, width, height = a.get_bbox().bounds\n    ax.annotate(label, xy=(left+width/2, bottom+height/2), ha='center', va='center', rotation=90, fontsize=28)\n#labels\nplt.ylabel(\"Count (mio.)\", fontsize=25) #ylabel\nplt.xlabel(\"Status: Accept up to 10 min. delay\", fontsize=25) #xlabel\nplt.title(\"Delay vs. On time (<10 min.)\", fontsize=30, fontname=\"Monospace\", alpha=.8) #title\nplt.xticks([]) #empty xticks\nplt.tight_layout(rect=[0, 0, 1, 1]) #tight layout\nplt.savefig('EDA_plot2.png', bbox_inches='tight') #save img\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### On time vs. delayed for each carrier ","metadata":{}},{"cell_type":"code","source":"#plot of delay for each carrier (stacked barchart)\n\n#data prep for plot\ncarier_delay_perc_plot = pd.DataFrame() #empty df\ncarier_delay_perc_plot['Carrier']=df['Carrier'] #carrier variable with full names\ncarier_delay_perc_plot['ontime']=df['delay']<=0 #on time vs. delay\ncarier_delay_perc_plot = carier_delay_perc_plot.groupby(['Carrier',\n                                                           'ontime']).size().unstack(1) #shape and class data\ncarier_delay_perc_plot = carier_delay_perc_plot.div(carier_delay_perc_plot.sum(axis=1), axis=0) #percentage\n\n#plot\nf, ax = plt.subplots(figsize=(10, 8))\ncarier_delay_perc_plot.sort_values(by=False).plot(kind=\"bar\", \n                                                  alpha=.9, stacked=True, ax=ax,color = palette) #stacked bar plot\n#set labels\nax.set_title(\"Percentage of delay by carrier\",fontsize = 30, fontname=\"Monospace\", alpha=.8) #title\nplt.xlabel('Carrier', fontsize = 16) #xlabel\nax.set_xticklabels(ax.get_xticklabels(), rotation=35, ha=\"right\") #rotate xlabel\nplt.ylabel(\"Percentage\", fontsize = 16) #ylabel\nax.legend(loc='upper right', title='On time', fontsize = 13)\nplt.gca().set_yticklabels([f'{x:.0%}' for x in plt.gca().get_yticks()]) #yticks in percentage\nplt.tight_layout(rect=[0, 0, 1, 1]) #tight rectangular layout\nplt.savefig('EDA_plot3.png', bbox_inches='tight') #save img\nplt.show() #plot","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The percentage of delay by carrier could perhaps be somewhat misleading (i.e. Hawaiian Airlines most on time flights, but surely a carrier like Delta or SouthWest Airlines must have more flights!) Let's explore the data a little further:\n","metadata":{}},{"cell_type":"code","source":"#create carrier total flights df\ndelay_carrier=df[['Carrier']].groupby(\"Carrier\").count() #carrier column and group by count\ndelay_carrier['fligts']=df['Carrier'].value_counts() #total flights\ndelay_carrier = delay_carrier.reset_index(drop=False) #reset index\n\n#carrier total delays df\ndelay_carrier2=(df[df['delay']>0]['Carrier'].value_counts()) #delayed\ndelay_carrier2=delay_carrier2.to_frame(name=('total delays')) #to df\ndelay_carrier2.index.name='Carrier' #set index name\ndelay_carrier2=delay_carrier2.reset_index(drop=False) #reset index\n\n#merge to carrier delay df\ndelay_merge = delay_carrier.merge(delay_carrier2[['Carrier','total delays']],\n                                  how='left',left_on='Carrier',right_on='Carrier')\ndelay_merge['percentage']=(delay_merge['total delays']/delay_merge['fligts']) #% delay column\ndelay_merge #explore new df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#multiple plots to gain better insight in delay by carrier.\n\n#plot total flights by carrier (should show that Hawaiian has way less flights than big carriers)\nf, ax = plt.subplots(figsize=(10, 8))\nsns.barplot(data= delay_merge.sort_values(by='fligts'),ax=ax, x=('Carrier'), y=('fligts'))\nax.set_title('Total flights by carrier',fontsize = 30, fontname=\"Monospace\", alpha=.8)\nax.set_xticklabels(ax.get_xticklabels(), rotation=35, ha=\"right\") #rotate xlabel\nax.set_xlabel('Carrier',fontsize = 16)\nax.set_ylabel(\"Count (mio.)\",fontsize = 16)\nplt.tight_layout(rect=[0, 0, 1, 1])\nplt.savefig('EDA_plot4.png', bbox_inches='tight') #save img\nplt.show() #plot\n\n#plot total delays by carrier\nf, ax = plt.subplots(figsize=(10, 8))\nsns.barplot(data= delay_merge.sort_values(by='total delays'),ax=ax, x=('Carrier'), y=('total delays'))\nax.set_title('Total delays by carrier')\nax.set_xticklabels(ax.get_xticklabels(), rotation=35, ha=\"right\") #rotate xlabel\nax.set_xlabel('Carrier')\nax.set_ylabel('No. of total delays')\nplt.tight_layout() #tight layout\nplt.show() #plot\n\n#plot percentage delays by carrier\nf, ax = plt.subplots(figsize=(10, 8))\nsns.barplot(data= delay_merge.sort_values(by='percentage'),ax=ax, x=('Carrier'), y=('percentage'))\nax.set_title('Percentge of delays by carrier', fontsize=20)\nax.set_xticklabels(ax.get_xticklabels(), rotation=35, ha=\"right\") #rotate xlabel\nax.set_xlabel('Carrier')\nax.set_ylabel('Percentage of delays')\nplt.tight_layout() #tight layout\nplt.show() #plot","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#merge df with airports, origin \ndelay_by_airport = pd.merge(df, airports,  how='inner', left_on=['Origin'], right_on = ['iata'])\ndelay_by_airport #explore\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create airport total flights df\ndelay_by_airport1 = delay_by_airport[['airport','iata']].groupby('airport').count()\ndelay_by_airport1.rename(columns={'iata': 'flights'}, inplace=True)\ndelay_by_airport1 = delay_by_airport1.sort_values(by=['flights'], ascending=False)\ndelay_by_airport1 = delay_by_airport1.reset_index(drop=False)\n\n#carrier total delays df\ndelay_by_airport2=(delay_by_airport[delay_by_airport['delay']>0]['airport'].value_counts()) #delayed\ndelay_by_airport2=delay_by_airport2.to_frame(name=('total delays')) #to df\ndelay_by_airport2.index.name='airport' #set index name\ndelay_by_airport2=delay_by_airport2.reset_index(drop=False) #reset index\n\n#merge to carrier delay df\ndelay_by_airport_merge = delay_by_airport1.merge(delay_by_airport2[['airport','total delays']],\n                                  how='left',left_on='airport',right_on='airport')\ndelay_by_airport_merge['percentage']=(delay_by_airport_merge['total delays']/delay_by_airport_merge['flights']) #% delay column\ndelay_by_airport_merge = delay_by_airport_merge.head(10)\ndelay_by_airport_merge #explore new df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#multiple airport plots\n\n#total flights \nf, ax = plt.subplots(figsize=(10, 8))\nsns.barplot(data= delay_by_airport_merge.sort_values(by='flights'),ax=ax, x=('airport'), y=('flights'))\nax.set_title('Total flights by airport', fontsize=20)\nax.set_xticklabels(ax.get_xticklabels(), rotation=35, ha=\"right\") #rotate xlabel\nax.set_xlabel('airport')\nax.set_ylabel(\"Count\")\nplt.tight_layout()\nplt.show() #plot\n\n#total delay\nf, ax = plt.subplots(figsize=(10, 8))\nsns.barplot(data= delay_by_airport_merge.sort_values(by='total delays'),ax=ax, x=('airport'), y=('total delays'))\nax.set_title('Total delays by airport', fontsize=20)\nax.set_xticklabels(ax.get_xticklabels(), rotation=35, ha=\"right\") #rotate xlabel\nax.set_xlabel('airport')\nax.set_ylabel('No. of total delays')\nplt.tight_layout() #tight layout\nplt.show() #plot\n\n#percentage of delays\nf, ax = plt.subplots(figsize=(10, 8))\nsns.barplot(data= delay_by_airport_merge.sort_values(by='percentage'),ax=ax, x=('airport'), y=('percentage'))\nax.set_title('Percentage of delays by airport', fontsize=20)\nax.set_xticklabels(ax.get_xticklabels(), rotation=35, ha=\"right\") #rotate xlabel\nax.set_xlabel('airport')\nax.set_ylabel('Percentage of delays')\nplt.tight_layout() #tight layout\nplt.show() #plot","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#average delay in minutes by weekday (departure, arrival, and total delay)\n\n#map days\ndf['DayOfWeek'] = df['DayOfWeek'].map({1:'Monday',2:'Tuesday',\n                                       3:'Wednesday',4:'Thursday',5:'Friday',\n                                       6:'Saturday',7:'Sunday'}).astype('str') #weekname column  \n#create df with average values\nday_mean=df[['DayOfWeek','DepDelay','ArrDelay']].groupby(['DayOfWeek']).mean() #mean delay by day\nday_mean['Avg. delay']=(day_mean['DepDelay']+day_mean['ArrDelay'])/2 #avg. delay column\nday_mean['Total avg. delay']=(day_mean['DepDelay']+day_mean['ArrDelay']) #tot. delay column\nday_mean=day_mean.sort_values(by='Avg. delay',ascending=True) #arrange by avg. delay\n\n#export table to img\nday_mean = day_mean.reset_index(drop=False)\nday_mean.rename(columns={'DayOfWeek': 'Day of Week', 'DepDelay': \n                         'Avg. Departure Delay','ArrDelay':\n                         'Avg. Arrival Delay'}, inplace=True) #rename columns\nday_mean_style = day_mean.style.background_gradient() #style table\ndfi.export(day_mean_style,\"Q1_1_table1.png\") #export to png\nday_mean_style #explore\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot bar chart mean delay delays total\n\n#reset plot style for next to plots (to match color of bars)\nsns.reset_orig()\nsns.set_style(\"whitegrid\")\n\nf, ax = plt.subplots(figsize=(10, 6))\nsns.barplot(data = day_mean.sort_values(by='Total avg. delay'), \n            ax=ax, alpha=.8, x=('Day of Week'), y=('Total avg. delay'))\n\nax.set_title('Average delay of weekday (min.)', fontsize=30, fontname=\"Monospace\", alpha=.8) #title\nax.set_xticklabels(ax.get_xticklabels(), rotation=35, ha=\"right\", fontsize = 15) #rotate xlabel\nax.set_ylabel('Avg. delay (min)', fontsize = 20)\nax.set_xlabel(xlabel=None) #remove obvioius xlabel\nplt.tight_layout(rect=[0, 0, 1, 1]) #tight layout rect\nplt.savefig('Q1_1_plot1.png', bbox_inches='tight') #save png\nplt.show() #plot","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#total flights/delays and percentage of delays by weekday (total delay)\n\n#df with total no. of delay occrurences by weekday in percentage\nday_total1=df[['DayOfWeek','delay']]\nday_total1=df[['DayOfWeek','delay']].groupby(['DayOfWeek']).count() #group by day and count total per day.\nday_total1['Flights(%)']=(day_total1['delay']/14007604)*100 #delay delays/ total flights in dataset\nday_total1.rename(columns={'delay': 'Flights'}, inplace=True)\n\n#total delays by weekday\nday_total2 = df[['DayOfWeek','DepDelay','ArrDelay']]\nday_total2 = (day_total2[(day_total2['DepDelay']>0) | (day_total2['ArrDelay']>0)])\nday_total2.rename(columns={'DepDelay': 'Delays'}, inplace=True)\nday_total2=day_total2.groupby(['DayOfWeek']).count()\nday_total2.drop(['ArrDelay'], inplace=True, axis=1) #drop columns\nday_total2\n\n#merge on DayofWeek\nday_total = pd.merge(day_total1, day_total2,  how='inner', left_on=['DayOfWeek'], \n                     right_on = ['DayOfWeek'])\nday_total['Delays (%)'] = (day_total['Delays']/day_total['Flights']) #create delay in percentage column\nday_total = day_total.sort_values(by='Delays (%)',ascending=True)#sort values\n\n#prettify table\nday_total = day_total.reset_index(drop=False)\nday_total.rename(columns={'DayOfWeek': 'Day of Week'}, inplace=True)\nday_total_style = day_total.style.background_gradient()\ndfi.export(day_total_style,\"Q1_1_table2.png\")\n\nday_total_style","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_palette = sns.color_palette(\"colorblind\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot bar chart mean delay delays total\nf, ax = plt.subplots(figsize=(10, 6))\n\npalette=['C1','C0','C2','C4','C3','C5','C6','c8'] #manually set day-color to match previous plot \n\nsns.barplot(data = day_total[['Day of Week','Delays (%)']],ax=ax,alpha=.8, palette=palette, \n            x=('Day of Week'), y=('Delays (%)'))\n\nax.set_title('Average delay of weekday (%)', fontsize=30, fontname=\"Monospace\", alpha=.8)\nax.set_xticklabels(ax.get_xticklabels(), rotation=35, ha=\"right\", fontsize = 15) #rotate xlabel\nax.set_ylabel('Percentage', fontsize = 20)\nax.set_xlabel(xlabel=None) #remove obvioius xlabel\nplt.gca().set_yticklabels([f'{x:.0%}' for x in plt.gca().get_yticks()]) \nplt.tight_layout(rect=[0, 0, 1, 1]) #tight layout\nplt.savefig('Q1_1_plot2.png', bbox_inches='tight')\nplt.show() #plot","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#set plotting style for following plots in notebook\nsns.reset_orig()\nplt.style.use('seaborn-colorblind')\nsns.set_style(\"whitegrid\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check for missing outliers\nprint(df['ArrTime'].isna().sum())\nprint(df['ArrTime'].value_counts())\n\nprint(df['DepTime'].isna().sum())\ndf['DepTime'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create bins with time of the day for ArrTime and DepTime\ndef condition1(i): \n    if i >= 0 and i <=600: return 'night'\n    if i > 600 and i <=1200: return 'before noon'\n    if i > 1200 and i <=1800: return 'afternoon'\n    if i > 1800 and i <=2400: return 'evening'\n    else: return 'other' #group invalid time entries (i.e 2600 in military time is not valid)\n\ndf['arr_time_bin']=df['ArrTime'].apply(condition1) #apply conditions to departure\ndf['dep_time_bin']=df['DepTime'].apply(condition1) #apply conditions to arrival\n\n#choose related columns for df\ntime_day = df[['ArrTime','CRSArrTime','ArrDelay','DepTime','CRSDepTime',\n               'DepDelay','delay','arr_time_bin', 'dep_time_bin']]\ntime_day =  time_day[(time_day['dep_time_bin'] != 'other') & \n                     (time_day['arr_time_bin'] != 'other')] #exclude 'none' = invalid time\ntime_day #explore","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#explore time bins for departure and arrival\nprint(time_day.arr_time_bin.value_counts())\nprint(time_day.dep_time_bin.value_counts())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create time of day table for flights, delays, and delays %.\n\n#total flights departure\ntime_day_dep=time_day[['dep_time_bin','delay']] #select columns\ntime_day_dep=time_day[['dep_time_bin','delay']].groupby(['dep_time_bin']).count() #group by day and count total per day.\ntime_day_dep = time_day_dep.reset_index(drop=False) #reset index\ntime_day_dep.rename(columns={'delay': 'Flights','dep_time_bin':'Time of day'}, inplace=True) #rename\n\n#total flights arrival\ntime_day_arr=time_day[['arr_time_bin','delay']] #select columns\ntime_day_arr=time_day[['arr_time_bin','delay']].groupby(['arr_time_bin']).count() #group by day and count total per day.\ntime_day_arr = time_day_arr.reset_index(drop=False) #reset index\ntime_day_arr.rename(columns={'delay': 'Flights','arr_time_bin': 'Time of day'}, inplace=True)  #rename\n\n#merge departure and arrival flights\ntime_day_tot_comb = pd.merge(time_day_dep, time_day_arr,  how='left', \n                             left_on=['Time of day'], right_on = ['Time of day'])\ntime_day_tot_comb['Flights'] = time_day_tot_comb['Flights_x']+time_day_tot_comb['Flights_y']\ntime_day_tot_comb = time_day_tot_comb[['Time of day','Flights']]\n\n#create delay column for departure2\ntime_day_dep2 = time_day[['dep_time_bin','DepDelay']]\ntime_day_dep2 = (time_day_dep2[(time_day_dep2['DepDelay']>0)])\ntime_day_dep2 = time_day_dep2.groupby(['dep_time_bin']).count()\ntime_day_dep2 = time_day_dep2.reset_index(drop=False)\ntime_day_dep2.rename(columns={'DepDelay': 'Total dep. delay','dep_time_bin':\n                              'Time of day'}, inplace=True)\n\n#create delay column for arrival2\ntime_day_arr2 = time_day[['arr_time_bin','ArrDelay']]\ntime_day_arr2 = (time_day_arr2[(time_day_arr2['ArrDelay']>0)])\ntime_day_arr2 = time_day_arr2.groupby(['arr_time_bin']).count()\ntime_day_arr2 = time_day_arr2.reset_index(drop=False)\ntime_day_arr2.rename(columns={'ArrDelay': 'Total arr. delay','arr_time_bin':\n                              'Time of day'}, inplace=True)\n\n\n#merge departure and arrival delays\ntime_day_tot_comb2 = pd.merge(time_day_dep2, time_day_arr2,  how='left', \n                              left_on=['Time of day'], right_on = ['Time of day'])\ntime_day_tot_comb2['Delays'] = time_day_tot_comb2['Total dep. delay']+time_day_tot_comb2['Total arr. delay']\n\n#merge all df's\ntime_day_df = pd.merge(time_day_tot_comb, time_day_tot_comb2,  how='left', \n                       left_on=['Time of day'], right_on = ['Time of day'])\ntime_day_df['Delayed (%)'] = (time_day_df['Delays']/time_day_df['Flights'])*100\ntime_day_df = time_day_df.sort_values(by='Delayed (%)',ascending=True)\n\ntime_day_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#selct varibales and prettify table\ntime_day_df = time_day_df[['Time of day','Flights','Delays','Delayed (%)']]\ntime_day_df.rename(columns={'dep_time_bin': 'Time of Day'}, inplace=True)\ntime_day_df_style = time_day_df.style.background_gradient()\ndfi.export(time_day_df_style,\"Q1_2_table1.png\") #to png\ntime_day_df_style","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot bar chart total delay delays total for day\nf, ax = plt.subplots(figsize=(10, 5))\nsns.barplot(data = time_day_df.sort_values(by='Delayed (%)'),ax=ax,alpha=.8, x=('Time of day'), y=('Delayed (%)'))\n#labels\nax.set_title('Percentage of delays by time of day', fontsize=30, fontname=\"Monospace\", alpha=.8)\nax.set_xticklabels(ax.get_xticklabels(), rotation=35, ha=\"right\", fontsize = 15) #rotate xlabel\nax.set_xlabel(xlabel=None) #remove obvioius xlabel\nax.set_ylabel('Percentage', fontsize = 16)\nplt.tight_layout(rect=[0, 0, 1, 1]) #tight layout\nplt.savefig('Q1_2_plot1.png', bbox_inches='tight')\nplt.show() #plot","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#mean of arrival delay\ntime_day_arr_mean = time_day[['ArrDelay','arr_time_bin']].groupby(['arr_time_bin']).mean().reset_index(drop=False)\ntime_day_arr_mean.rename(columns={'arr_time_bin': 'Time of day','ArrDelay':'Avg. Arrival Delay'}, inplace=True)\n\n#mean of departure delay\ntime_day_dep_mean = time_day[['DepDelay','dep_time_bin']].groupby(['dep_time_bin']).mean().reset_index(drop=False)\ntime_day_dep_mean.rename(columns={'dep_time_bin': 'Time of day','DepDelay':'Avg. Departure Delay'}, inplace=True)\n\n# merge and create total column\ntime_day_mean_comb = pd.merge(time_day_dep_mean, time_day_arr_mean,  how='left', left_on=['Time of day'], right_on = ['Time of day'])\ntime_day_mean_comb['Total avg. Delays'] = (time_day_mean_comb['Avg. Departure Delay'] + time_day_mean_comb['Avg. Arrival Delay'])\ntime_day_mean_comb=time_day_mean_comb.sort_values(by='Total avg. Delays',ascending=True)\n\n#style table\ntime_day_mean_comb_style = time_day_mean_comb.style.background_gradient()\ndfi.export(time_day_mean_comb_style,\"Q1_2_table2.png\")\ntime_day_mean_comb_style","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot bar chart total delay delays total for day\nf, ax = plt.subplots(figsize=(10, 5))\n\npalette=['C0','C2','C3','C1'] #set color to match days in previous plot\n\nsns.barplot(data = time_day_mean_comb.sort_values(by='Total avg. Delays'),ax=ax,alpha=.8, x=('Time of day'), y=('Total avg. Delays'),palette=palette)\n\nax.set_title('Average delay by time of day', fontsize=30, fontname=\"Monospace\", alpha=.8)\nax.set_xticklabels(ax.get_xticklabels(), rotation=35, ha=\"right\", fontsize = 15) #rotate xlabel\nax.set_xlabel(xlabel=None) #remove obvioius xlabel\nax.set_ylabel('Minutes', fontsize = 16)\nplt.tight_layout(rect=[0, 0, 1, 1]) #tight layout\nplt.savefig('Q1_2_plot2.png', bbox_inches='tight')\nplt.show() #plot","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#map months\ndf['Month'] = df['Month'].map({1:'January',2:'February',3:'March',4:'April',5:'May',\n                               6:'June',7:'July',8:'August',9:'September',10:'October',\n                               11:'November',12:'December'})\n#df grouped by mean of month \nmonth_mean=df[['Month','DepDelay','ArrDelay']].groupby(['Month']).mean().reset_index(drop=False)\nmonth_mean['Total Avg. Delay']=(month_mean['DepDelay']+month_mean['ArrDelay']) #mean of the delays\nmonth_mean.rename(columns={'DepDelay': 'Departure delay','ArrDelay':'Arrival Delay'}, inplace=True)\nmonth_mean = month_mean.sort_values(by='Total Avg. Delay',ascending=True)\nmonth_mean_style = month_mean.style.background_gradient() #style\ndfi.export(month_mean_style,\"Q1_3_table1.png\") #save to png\nmonth_mean_style #explore","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#total no. of delay occrurences by weekday in percentage\n#month_total1=df[['Month','delay']]\nmonth_total1=df[['Month','delay']].groupby(['Month']).count() #group by day and count total per day.\nmonth_total1['Flights(%)']=(month_total1['delay']/14007604)*100 #delay delays/ total flights in dataset\nmonth_total1.rename(columns={'delay': 'Flights'}, inplace=True)\n\n#total delays by month\nmonth_total2 = df[['Month','DepDelay','ArrDelay']]\nmonth_total2 = (month_total2[(month_total2['DepDelay']>0) | (month_total2['ArrDelay']>0)])\nmonth_total2.rename(columns={'DepDelay': 'Delays'}, inplace=True)\nmonth_total2=month_total2.groupby(['Month']).count()\nmonth_total2.drop(['ArrDelay'], inplace=True, axis=1) #drop columns\n\n#merge on DayofWeek\nmonth_total = pd.merge(month_total1, month_total2,  how='inner', left_on=['Month'], right_on = ['Month'])\n\n#create delay in percentage column\nmonth_total['Delayed (%)'] = month_total['Delays']/month_total['Flights']*100\n\n\n#sort values\nmonth_total = month_total.sort_values(by='Delayed (%)',ascending=True)\n\n#export cell (dataframe_image library)\nmonth_total = month_total.reset_index(drop=False)\nmonth_total_style = month_total.style.background_gradient()\ndfi.export(month_total_style,\"Q1_3_table2.png\")\nmonth_total_style","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#piechart of average delay month\n\n#data prep\nmonth_order = ['January', 'February', 'March', 'April', 'May', 'June', 'July', \n               'August', 'September', 'October', 'November', 'December'] #list order\nmonth_mean[\"Months\"] = pd.Categorical(month_mean[\"Month\"], categories=month_order) #map order\nmonth_mean = month_mean.sort_values(by='Months') #sort\n\n#pie chart\nf, ax = plt.subplots(figsize=(10, 8))\nexplode = [0.005, 0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.15,0.005,0.005,0.005] #explode september\n#create pie chart\nplt.pie(month_mean['Total Avg. Delay'], labels= month_mean['Months'], colors = sns.color_palette('pastel')[2:13], \n        explode = explode, autopct='%.2f%%') #plot\nplt.title('Delay dist. by month (%)', fontsize=18, fontname=\"Monospace\", alpha=.8) #title\nplt.savefig('Q1_3_plot1.png', bbox_inches='tight') #save to png\nplt.show() #plot","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"season_total = month_total\n\n#season total with function\ndef label1 (row):\n   if row['Month'] == 'March' or row['Month'] == 'April' or row['Month'] == 'May':\n      return 'Spring'\n   if row['Month'] == 'June' or row['Month'] == 'July' or row['Month'] == 'August':\n      return 'Summer'\n   if row['Month'] == 'September' or row['Month'] == 'October' or row['Month'] == 'November':\n      return 'Autumn'\n   if row['Month'] == 'January' or row['Month'] == 'February' or row['Month'] == 'December':\n      return 'Winter'\n   return 'Other'\nseason_total['Month']=season_total.apply(lambda row: label1(row), axis=1)\n\n#group and calculate season total df\nseason_total = season_total.groupby(['Month']).sum().reset_index(drop=False)\nseason_total['Delayed (%)'] = season_total['Delayed (%)']/3\nseason_total.rename(columns={'Month': 'Season'}, inplace=True)\nseason_total_style = season_total.style.background_gradient()\ndfi.export(season_total_style,\"Q1_3_table3.png\")\nseason_total_style","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#same for mean:\nseason_mean = month_mean\ndef label2 (row):\n   if row['Month'] == 'March' or row['Month'] == 'April' or row['Month'] == 'May':\n      return 'Spring'\n   if row['Month'] == 'June' or row['Month'] == 'July' or row['Month'] == 'August':\n      return 'Summer'\n   if row['Month'] == 'September' or row['Month'] == 'October' or row['Month'] == 'November':\n      return 'Autumn'\n   if row['Month'] == 'January' or row['Month'] == 'February' or row['Month'] == 'December':\n      return 'Winter'\n   return 'Other'\nseason_mean['Month']=season_mean.apply(lambda row: label2(row), axis=1)\n\n#group and calculate season total df\nseason_mean = season_mean.groupby(['Month']).sum().reset_index(drop=False)\nseason_mean.rename(columns={'Month': 'Season','Departure delay':'Dep. delay (min)',\n                            'Arrival Delay':'Arr. delay (min)'}, inplace=True)\nseason_mean_style = season_mean.style.background_gradient()\ndfi.export(season_mean_style,\"Q1_3_table4.png\")\nseason_mean_style","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#combine plane dataframe with planedata\ndf_airplanes= df.merge(airplanes[['tailnum','year']],how='left',left_on='TailNum',\n                       right_on='tailnum') #join\ndf_airplanes=df_airplanes[df_airplanes['year'].isnull()==False] #exlude\n\n#rename year from airplanes (to avoid confusion)\ndf_airplanes.rename(columns={'year': 'plane_year'}, inplace=True)\ndf_airplanes #explore \n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_airplanes.isna().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#NA's in plane_year is zero, but a closer look reveals the some values = None(a missing value)\ndf_airplanes.value_counts('plane_year').head(15)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#exclude the 'None' values\ndf_airplanes = df_airplanes[df_airplanes.plane_year != 'None']\ndf_airplanes.value_counts('plane_year').head(15) #verify","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_airplanes['plane_year'].dtype #check dtype","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_airplanes['plane_year'] = df_airplanes['plane_year'].astype(int) #change to integer\ndf_airplanes['plane_year'].dtype #verify","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#categorise the planes either as old or new by manifacturing year\nbins = [1920,1987,2022]\nlabels=['old','new']\ndf_airplanes['plane_condition'] = pd.cut(df_airplanes['plane_year'], bins=bins, labels=labels)\n\n#create a delayed boolean column \ndf_airplanes['Delayed_bool'] = (df_airplanes['DepDelay']>0) | (df_airplanes['ArrDelay']>0)\ndf_airplanes['Delayed_bool'] = df_airplanes['Delayed_bool']*1\n\ndf_airplanes_bin=df_airplanes[['plane_condition','plane_year','delay','Delayed_bool', 'ArrDelay','DepDelay']]\ndf_airplanes_bin","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_airplanes_bin.isna().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#the new NA's is must be occuring due to the year bins, let's adress these:\n\n#check for outlier values\nprint(df_airplanes_bin['plane_year'].min())\nprint(df_airplanes_bin['plane_year'].max())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#0 is definetely not a correct value for manufacturing year, lets drop theese.\n\ndf_airplanes_bin = df_airplanes_bin[df_airplanes_bin['plane_year'] > 1900] #exclude 0\nprint(df_airplanes_bin['plane_year'].min())\nprint(df_airplanes_bin['plane_year'].max())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Year 1956 seems more likely to be the manifacturing year of the oldest plane.\n#NA's in df_airplanes should now be zero.\ndf_airplanes_bin.isna().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Total no. of old and new planes\ndf_airplanes_bin.plane_condition.value_counts()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#total no. of delay occrurences by weekday in percentage\ndf_airplanes_bin1=df_airplanes_bin[['plane_condition','delay']].groupby(['plane_condition']).count() #group by day and count total per day.\ndf_airplanes_bin1['Flights(%)']=(df_airplanes_bin1['delay']/(10100221+1232687) )*100 #divide with total flights by old and new planes\ndf_airplanes_bin1.rename(columns={'delay': 'Flights'}, inplace=True)\ndf_airplanes_bin1\n\n#total delays by weekday\ndf_airplanes_bin2 = df_airplanes_bin[['plane_condition','Delayed_bool']].groupby(['plane_condition']).sum()\ndf_airplanes_bin2.rename(columns={'Delayed_bool': 'Delays'}, inplace=True)\n\ndf_airplanes_tab = pd.merge(df_airplanes_bin1, df_airplanes_bin2,  how='inner', left_on=['plane_condition'], right_on = ['plane_condition'])\n\n#create delay in percentage column\ndf_airplanes_tab['Delayed (%)'] = df_airplanes_tab['Delays']/df_airplanes_tab['Flights']*100\n\n#sort values\ndf_airplanes_tab = df_airplanes_tab.sort_values(by='Delayed (%)',ascending=True)\n\n#export cell (dataframe_image library)\ndf_airplanes_tab = df_airplanes_tab.reset_index(drop=False)\ndf_airplanes_tab.rename(columns={'plane_condition': 'Plane Condition'}, inplace=True)\ndf_airplanes_tab_style = df_airplanes_tab.style.background_gradient()\ndfi.export(df_airplanes_tab_style,\"Q2_table1.png\")\ndf_airplanes_tab_style","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#airplane mean by manu. year\ndf_airplanes_mean=df_airplanes_bin[['plane_condition',\n                                    'DepDelay','ArrDelay','delay']].groupby(['plane_condition']).mean().reset_index(drop=False) #group\ndf_airplanes_mean.rename(columns={'delay': \n                                  'Total avg. delay','ArrDelay':'Avg. Arrival Delay',\n                                  'DepDelay':'Avg. Departure Delay','plane_condition': 'Plane Condition'}, inplace=True) #rename\ndf_airplanes_mean = df_airplanes_mean.sort_values(by='Total avg. delay',ascending=True) #sort\ndf_airplanes_mean_style = df_airplanes_mean.style.background_gradient()\ndfi.export(df_airplanes_mean_style,\"Q2_table2.png\")\ndf_airplanes_mean_style","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#merge the tables\n\ndf_airplanes_comb = pd.merge(df_airplanes_tab,df_airplanes_mean,  how='inner', left_on=['Plane Condition'], right_on = ['Plane Condition'])\n\ndf_airplanes_comb_style = df_airplanes_comb.style.background_gradient() #style\ndfi.export(df_airplanes_comb_style,\"Q2_table3.png\") #export to png\ndf_airplanes_comb_style #explore","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot mean delay\n\ndf_airplanes_mean = df_airplanes_mean.reset_index(drop=False)\n\n#plot barchart\nf, ax = plt.subplots(figsize=(10, 7))\n\ndf_airplanes_mean.plot(kind = 'bar',ax=ax, x='Plane Condition',y='Total avg. delay', color=['indianred', 'olivedrab'],legend=None)\n\n#set labels\nax.set_title(\"Mean delay: Old vs. New\", fontsize=17) #title\nplt.ylabel(\"Mean delay\") #ylabel\nax.set_xticklabels(ax.get_xticklabels(), rotation=0, ha=\"center\",fontsize=14 ) #rotate xlabel\n#plt.tight_layout() #tight layout\nplt.show() #plot","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot data prep\ncondition_data=[20.436394,20.647952] \ncondition_dec = pd.Series(index = [\"New planes\", \"Old planes\"], data=condition_data) #create series\npercentage = condition_dec.div(condition_dec.sum()).mul(100).round(2) #calc. the percentage and round 2 dec\n\n\n\n#barplot \nax = condition_dec.plot(kind=\"bar\", alpha=0.7, figsize=(10, 8), color=palette)\n#set labels inside the bars\nlabels = [f'{condition_dec} - {percentage[condition_dec]}%' for condition_dec in condition_dec.index]\nfor label, a in zip(labels, ax.patches):\n    left, bottom, width, height = a.get_bbox().bounds\n    ax.annotate(label, xy=(left+width/2, bottom+height/2), ha='center', va='center', rotation=90, fontsize=28)\n#labels\nplt.ylabel(\"Minutes\", fontsize=25) #ylabel\nplt.xlabel(\"Plane condition\", fontsize=25) #xlabel\nplt.title(\"Mean time of delays for planes\", fontsize=30, fontname=\"Monospace\", alpha=.8) #title\nplt.xticks([]) #empty xticks\nplt.tight_layout(rect=[0, 0, 1, 1]) #tight layout (rectangular)\nplt.savefig('Q2_plot1.png', bbox_inches='tight') #save img\nplt.show()\n\n#same for total delays by plane:\n#data prep\ncondition_data2=[55.906308,57.950508] \ncondition_dec2 = pd.Series(index = [\"New planes - 55.91\", \"Old planes - 57.95\"], data=condition_data2) #create series\n\n#barplot \nax = condition_dec2.plot(kind=\"bar\", alpha=0.7, figsize=(10, 8), color=palette)\n#set labels inside the bars\nlabels = [f'{condition_dec2}%' for condition_dec2 in condition_dec2.index]\nfor label, a in zip(labels, ax.patches):\n    left, bottom, width, height = a.get_bbox().bounds\n    ax.annotate(label, xy=(left+width/2, bottom+height/2), ha='center', va='center', rotation=90, fontsize=28)\n#labels\nplt.ylabel(\"Percentage\", fontsize=25) #ylabel\nplt.xlabel(\"Plane condition\", fontsize=25) #xlabel\nplt.title(\"Percentage of delayed flight\", fontsize=30, fontname=\"Monospace\", alpha=.8) #title\nplt.xticks([]) #empty xticks\nplt.tight_layout(rect=[0, 0, 1, 1]) #tight layout (rectangular)\nplt.savefig('Q2_plot2.png', bbox_inches='tight') #save img\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#chi-squared test\n\n#create a contingency table\nairplane_contingency  = pd.crosstab(df_airplanes['plane_condition'],\n                            df_airplanes['Delayed_bool'],\n                           margins=True, margins_name=\"Total\") #margins=true adds total column\nairplane_contingency #explore table\n\n#calculate relation\nchi2, p, expected,dof  = chi2_contingency(airplane_contingency)\nprint(\"H0: Old planes does not suffer more delay VS. H1:Old planes suffer more delay \")\nprint(f\"P Value:            {p:.4f}\")\nif p >=0.05:\n  print(\"We reject the null hypotheses at a 5% significance level\") #% significance level\nelse:\n  print(\"We FAIL reject the null hypotheses at a 5% significance level\")\n\n#we also test at a 10% significance level due to the close mean values\nif p >=0.10:\n  print(\"We reject the null hypotheses at a 10% significance level\") #10% significance level\nelse:\n  print(\"We also FAIL reject the null hypotheses at a 10% significance level\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#categorise the planes either as old or new by manifacturing year\nbins = [0,1987,1997,2022]\nlabels=['1956-1987(old)','1987-1997(mid)','1997-2007(new)']\ndf_airplanes['plane_condition2'] = pd.cut(df_airplanes['plane_year'], bins=bins, labels=labels)\ndf_airplanes_bin2=df_airplanes[['plane_condition2','plane_year','delay','Delayed_bool', \n                                'ArrDelay','DepDelay']]\n\n#group by condition and mean\ndf_airplanes_mean2=df_airplanes_bin2[['plane_condition2',\n                                      'DepDelay','ArrDelay',\n                                      'delay']].groupby(['plane_condition2']).mean().reset_index(drop=False)\ndf_airplanes_mean2.rename(columns={'plane_condition2':\n                                   'Plane Condition','delay': 'Total avg. delay','ArrDelay':\n                                   'Avg. Arrival Delay','DepDelay':\n                                   'Avg. Departure Delay'}, inplace=True)\ndf_airplanes_mean2 = df_airplanes_mean2.sort_values(by='Total avg. delay',ascending=True)\ndf_airplanes_mean2_style = df_airplanes_mean2.style.background_gradient() #style\ndfi.export(df_airplanes_mean2_style,\"Q2_table4.png\") #export to png\ndf_airplanes_mean2_style #explore","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#total no. of delay occrurences by weekday in percentage\ndf_airplanes_bin2_1=df_airplanes_bin2[['plane_condition2','delay']].groupby(['plane_condition2']).count() #group by day and count total per day.\ndf_airplanes_bin2_1.rename(columns={'delay': 'Flights'}, inplace=True)\ndf_airplanes_bin2_1['Flights(%)']=(df_airplanes_bin2_1['Flights']/11332781 )*100 #divide with total flights by old and new planes\n\n\n#total delays by weekday\ndf_airplanes_bin2_2 = df_airplanes_bin2[['plane_condition2','Delayed_bool']].groupby(['plane_condition2']).sum()\ndf_airplanes_bin2_2.rename(columns={'Delayed_bool': 'Delays'}, inplace=True)\n\n#merge on plane condition\ndf_airplanes_bin2_tab = pd.merge(df_airplanes_bin2_1, df_airplanes_bin2_2,  how='inner', left_on=['plane_condition2'], right_on = ['plane_condition2'])\n\n#create delay in percentage column\ndf_airplanes_bin2_tab['Delayed (%)'] = df_airplanes_bin2_tab['Delays']/df_airplanes_bin2_tab['Flights']*100\n\n#create delay in percentage column\ndf_airplanes_bin2_tab['Delayed (%)'] = df_airplanes_bin2_tab['Delays']/df_airplanes_bin2_tab['Flights']*100\ndf_airplanes_bin2_tab=df_airplanes_bin2_tab.reset_index(drop=False)\ndf_airplanes_bin2_tab.rename(columns={'plane_condition2': 'Plane Condition'}, inplace=True)\n\n\ndf_airplanes_bin_comb = pd.merge(df_airplanes_bin2_tab,df_airplanes_mean2,  how='inner', left_on=['Plane Condition'], right_on = ['Plane Condition'])\n\ndf_airplanes_bin_comb_style = df_airplanes_bin_comb.style.background_gradient() #style\ndfi.export(df_airplanes_bin_comb_style,\"Q2_table5.png\") #export to png\ndf_airplanes_bin_comb_style #explore","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_airplanes_mean2 = df_airplanes_mean2.reset_index(drop=False)\n\n#plot barchart\nf, ax = plt.subplots(figsize=(10, 7))\n\ndf_airplanes_mean2.plot(kind = 'bar',ax=ax, x='Plane Condition',y='Total avg. delay',color=['indianred', 'olivedrab', 'blue'],legend=None)\n\n#set labels\nax.set_title(\"Mean delay: Old vs. New\", fontsize=17) #title\nplt.ylabel(\"Mean delay\") #ylabel\nax.set_xticklabels(ax.get_xticklabels(), rotation=0, ha=\"center\",fontsize=14 ) #rotate xlabel\n#plt.tight_layout() #tight layout\nplt.show() #plot","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#prettify the plot for report\ncondition_data3=[20.127357,20.647952,21.079243] \ncondition_dec3 = pd.Series(index = [\"New planes\", \"Old planes\",'Mid planes'], data=condition_data3) #create series\npercentage3 = condition_dec3.div(condition_dec3.sum()).mul(100).round(2) #calc. the percentage and round 2 dec\n\n#barplot \nax = condition_dec3.plot(kind=\"bar\", alpha=0.7, figsize=(10, 8), color=palette)\n#set labels inside the bars\nlabels = [f'{condition_dec3} - {percentage3[condition_dec3]}%' for condition_dec3 in condition_dec3.index]\nfor label, a in zip(labels, ax.patches):\n    left, bottom, width, height = a.get_bbox().bounds\n    ax.annotate(label, xy=(left+width/2, bottom+height/2), ha='center', va='center', rotation=90, fontsize=28)\n#labels\nplt.ylabel(\"Minutes\", fontsize=25) #ylabel\nplt.xlabel(\"Plane condition\", fontsize=25) #xlabel\nplt.title(\"Mean time of delays for planes\", fontsize=30, fontname=\"Monospace\", alpha=.8) #title\nplt.xticks([]) #empty xticks\nplt.tight_layout(rect=[0, 0, 1, 1]) #tight layout (rectangular)\nplt.savefig('Q2_plot3.png', bbox_inches='tight') #save img\nplt.show()\n\n\n#prettify the plot for report\ncondition_data4=[55.35,57.95,57.07] \ncondition_dec4 = pd.Series(index = [\"New planes - 55.35\", \"Old planes - 57.95\",'Mid planes - 57.07'], data=condition_data3) #create series\n\n#barplot \nax = condition_dec3.plot(kind=\"bar\", alpha=0.7, figsize=(10, 8), color=palette)\n#set labels inside the bars\nlabels = [f'{condition_dec4}%' for condition_dec4 in condition_dec4.index]\nfor label, a in zip(labels, ax.patches):\n    left, bottom, width, height = a.get_bbox().bounds\n    ax.annotate(label, xy=(left+width/2, bottom+height/2), ha='center', va='center', rotation=90, fontsize=28)\n#labels\nplt.ylabel(\"Percentage\", fontsize=25) #ylabel\nplt.xlabel(\"Plane condition\", fontsize=25) #xlabel\nplt.title(\"Percentage of delayed flight\", fontsize=30, fontname=\"Monospace\", alpha=.8) #title\nplt.xticks([]) #empty xticks\nplt.tight_layout(rect=[0, 0, 1, 1]) #tight layout (rectangular)\nplt.savefig('Q2_plot4.png', bbox_inches='tight') #save img\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#load data for a ten year period, same encoding used for all.\ndf_97 = pd.read_csv(\"1997.csv\", usecols = [\"Origin\", \"Dest\", \"Year\"], encoding='latin-1')\ndf_98 = pd.read_csv(\"1998.csv\", usecols = [\"Origin\", \"Dest\", \"Year\"], encoding='latin-1')\ndf_99 = pd.read_csv(\"1999.csv\", usecols = [\"Origin\", \"Dest\", \"Year\"], encoding='latin-1')\ndf_00 = pd.read_csv(\"2000.csv\", usecols = [\"Origin\", \"Dest\", \"Year\"], encoding='latin-1')\ndf_01 = pd.read_csv(\"2001.csv\", usecols = [\"Origin\", \"Dest\", \"Year\"], encoding='latin-1')\ndf_02 = pd.read_csv(\"2002.csv\", usecols = [\"Origin\", \"Dest\", \"Year\"], encoding='latin-1')\ndf_03 = pd.read_csv(\"2003.csv\", usecols = [\"Origin\", \"Dest\", \"Year\"], encoding='latin-1')\ndf_04 = pd.read_csv(\"2004.csv\", usecols = [\"Origin\", \"Dest\", \"Year\"], encoding='latin-1')\ndf_05 = pd.read_csv(\"2005.csv\", usecols = [\"Origin\", \"Dest\", \"Year\"], encoding='latin-1')\ndf_06 = pd.read_csv(\"2006.csv\", usecols = [\"Origin\", \"Dest\", \"Year\"], encoding='latin-1') \ndf_07 = pd.read_csv(\"2007.csv\", usecols = [\"Origin\", \"Dest\", \"Year\"], encoding='latin-1')  \n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#group data and rename the year column to avoid confusion\ndf_97 = df_97.groupby(['Origin','Dest']).count().sort_values(by=['Year'], ascending=False)\ndf_97.rename(columns={'Year': '1997'}, inplace=True) #year 1997\ndf_98 = df_98.groupby(['Origin','Dest']).count().sort_values(by=['Year'], ascending=False)\ndf_98.rename(columns={'Year': '1998'}, inplace=True)#year 1998\ndf_99 = df_99.groupby(['Origin','Dest']).count().sort_values(by=['Year'], ascending=False)\ndf_99.rename(columns={'Year': '1999'}, inplace=True)#year 1999\ndf_00 = df_00.groupby(['Origin','Dest']).count().sort_values(by=['Year'], ascending=False)\ndf_00.rename(columns={'Year': '2000'}, inplace=True)#year 2000\ndf_01 = df_01.groupby(['Origin','Dest']).count().sort_values(by=['Year'], ascending=False)\ndf_01.rename(columns={'Year': '2001'}, inplace=True)#year 2001\ndf_02 = df_02.groupby(['Origin','Dest']).count().sort_values(by=['Year'], ascending=False)\ndf_02.rename(columns={'Year': '2002'}, inplace=True)#year 2002\ndf_03 = df_03.groupby(['Origin','Dest']).count().sort_values(by=['Year'], ascending=False)\ndf_03.rename(columns={'Year': '2003'}, inplace=True)#year 2003\ndf_04 = df_04.groupby(['Origin','Dest']).count().sort_values(by=['Year'], ascending=False)\ndf_04.rename(columns={'Year': '2004'}, inplace=True)#year 2004\ndf_05 = df_05.groupby(['Origin','Dest']).count().sort_values(by=['Year'], ascending=False)\ndf_05.rename(columns={'Year': '2005'}, inplace=True)#year 2005\ndf_06 = df_06.groupby(['Origin','Dest']).count().sort_values(by=['Year'], ascending=False)\ndf_06.rename(columns={'Year': '2006'}, inplace=True)#year 2006\ndf_07 = df_07.groupby(['Origin','Dest']).count().sort_values(by=['Year'], ascending=False)\ndf_07.rename(columns={'Year': '2007'}, inplace=True)#year 2007","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#specify dataframes to merge\ndata_frames = [df_97, df_98, df_99, df_00, df_01, df_02, df_03, df_04, df_05, df_06, df_07]\n\n#merge to one df\ndf_location = reduce(lambda  left,right: pd.merge(left,right,on=['Origin','Dest'],\n                                            how='left'), data_frames)\ndf_location #explore","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#see missing values\ndf_location.isna().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#replace with NaN with 0 because it represents a missing entry (i.e. no arrival or departure from airport).\ndf_location = df_location.replace(np.nan, 0)\n\n#verify\ndf_location.isnull().sum() ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create total column\ndf_location['Total'] = df_location.sum(axis=1)\ndf_location=df_location.sort_values(by=['Total'], ascending=False).reset_index(drop=False)\n\ndf_location","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#select top 20 locations\ntop20 = df_location.loc[0:19]\n\ndef label3 (row):\n   if row['Origin'] == 'LAX' and row['Dest'] == 'LAS':\n      return 'LAX&LAS'\n   if row['Origin'] == 'LAS' and row['Dest'] == 'LAX':\n      return 'LAX&LAS'\n   if row['Origin'] == 'PHX' and row['Dest'] == 'LAX':\n      return 'PHX&LAX'\n   if row['Origin'] == 'LAX' and row['Dest'] == 'PHX':\n      return 'PHX&LAX'\n   if row['Origin'] == 'SFO' and row['Dest'] == 'LAX':\n      return 'SFO&LAX'\n   if row['Origin'] == 'LAX' and row['Dest'] == 'SFO':\n      return 'SFO&LAX'\n   if row['Origin'] == 'ORD' and row['Dest'] == 'MSP':\n      return 'ORD&MSP'\n   if row['Origin'] == 'MSP' and row['Dest'] == 'ORD':\n      return 'ORD&MSP'\n   if row['Origin'] == 'PHX' and row['Dest'] == 'LAS':\n      return 'PHX&LAS'\n   if row['Origin'] == 'LAS' and row['Dest'] == 'PHX':\n      return 'PHX&LAS'\n   if row['Origin'] == 'LGA' and row['Dest'] == 'ORD':\n      return 'LGA&ORD'\n   if row['Origin'] == 'ORD' and row['Dest'] == 'LGA':\n      return 'LGA&ORD'\n   if row['Origin'] == 'HOU' and row['Dest'] == 'DAL':\n      return 'HOU&DAL'\n   if row['Origin'] == 'DAL' and row['Dest'] == 'HOU':\n      return 'HOU&DAL'\n   if row['Origin'] == 'OAK' and row['Dest'] == 'LAX':\n      return 'OAK&LAX'\n   if row['Origin'] == 'LAX' and row['Dest'] == 'OAK':\n      return 'OAK&LAX'\n   if row['Origin'] == 'EWR' and row['Dest'] == 'ORD':\n      return 'EWR&ORD'\n   if row['Origin'] == 'ORD' and row['Dest'] == 'EWR':\n      return 'EWR&ORD'\n   if row['Origin'] == 'BOS' and row['Dest'] == 'LGA':\n      return 'BOS&LGA'\n   if row['Origin'] == 'LGA' and row['Dest'] == 'BOS':\n      return 'BOS&LGA'\n   return 'Other'\n\ntop20['connection']=top20.apply(lambda row: label3(row), axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#group to top10 connections/routes\ntop10 = top20.groupby(\"connection\").sum().reset_index(drop=False) #sum \ntop10.rename(columns={'connection': 'Route'}, inplace=True) #rename\ntop10 = top10.sort_values(by=['Total'], ascending=False) #arrange by total column\ntop10 = top10.drop('Total', 1) #drop total column again.\n\n#convert to integer\nfor col in top10.columns:\n    if top10[col].dtype == np.float:\n        top10[col] = top10[col].astype(int)\n\ntop10_Style = top10.style.background_gradient() #prettify\ndfi.export(top10_Style,\"Q3_table1.png\") #export to image\ntop10_Style #explore","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot 11 year stacked\nf, ax = plt.subplots(figsize=(16, 8))\n\n\ncolors=['blue','red','green','gold','peru','olive','cyan',\n        'crimson','purple','steelblue','orange'] #colour\ntop10.set_index('Route').plot(kind='bar', stacked=True,ax=ax,color=colors) #plot\nax.legend(loc='upper right',title='Year', bbox_to_anchor=(1, 1),\n          ncol=4, fancybox=True, shadow=True) #legend\nplt.title('Location changes over time', fontsize=18) #title\nplt.ylabel('Number of flights') #ylabel\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plot of years that stand out a bit (including start and end year)","metadata":{}},{"cell_type":"code","source":"#data prep\nstart_to_end = top10[['Route','1997','2001','2002','2007']]\n\n#reset plot style for next to plots (to match color of bars)\nsns.reset_orig()\nsns.set_style(\"whitegrid\")\n\n#plot\nf,ax=plt.subplots(figsize=(12,7))\nstart_to_end.set_index('Route').plot(kind='bar',stacked=False,ax=ax, alpha=.8)\nax.legend(loc='upper right', title='Year', fontsize=12) #legend\n#title and labels,etc:\nax.set_title('Flights between locations (1997-2007)', fontsize=30, fontname=\"Monospace\", alpha=.8)\nax.set_xlabel(xlabel=None) #remove obvioius xlabel\nax.set_xticklabels(ax.get_xticklabels(), rotation=35, ha=\"right\", fontsize = 12) #rotate xlabel\nax.set_ylabel('No. of flights', fontsize=16) #ylab\nplt.savefig('Q3_plot1.png', bbox_inches='tight') #export png\nplt.show() ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#set plotting style for following plots in notebook\nsns.reset_orig()\nplt.style.use('seaborn-colorblind')\nsns.set_style(\"whitegrid\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot total flights over the years\n\n#data prep\ntop10_tot = top10 \ntop10_tot.loc['Total']= top10_tot.sum(numeric_only=True,axis=0)\ntop10_tot = top10_tot.fillna('All Routes')\ntot10_tot_data = top10_tot.iloc[10,1:12]\ntot10_tot_data = pd.DataFrame(tot10_tot_data)\n\n#plot\nf, ax = plt.subplots(figsize=(16, 8))\ntot10_tot_data.plot(kind='bar',ax=ax,color=palette)\nplt.title('Location changes over time', fontsize=18)\nplt.ylabel('Number of flights')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Exploration of the drop in 2001\ndf_2001 = pd.read_csv(\"2001.csv\", usecols = [\"Month\", \"UniqueCarrier\"], encoding='latin-1') #read data\ndf_2001 = df_2001.groupby(\"Month\").count().reset_index(drop=False) #count flights per month\ndf_2001['Month'] = df_2001['Month'].map({1:'January',2:'February',3:'March',4:'April',5:'May',6:'June',7:'July',8:'August',9:'September',10:'October',11:'November',12:'December'}).astype('str') #map names of months\n\n#plot data\nf,ax=plt.subplots(figsize=(12,7))\nax.plot(df_2001['Month'], df_2001['UniqueCarrier'], alpha=0.8,linewidth=3)\nplt.title(\"Exploration of drop in 2001\", fontsize=30, fontname=\"Monospace\", alpha=.8)\nax.set_xlabel(xlabel=None) #remove obvioius xlabel\nplt.ylabel('Total no. of flights', fontsize=16)\nplt.savefig('Q3_plot2.png', bbox_inches='tight')\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create df's\nplane_delay = df #df for airplanes\ndf_airport = df #df for airports\n\n#select columns\nplane_delay= plane_delay[['TailNum','Origin','Dest','DepDelay','ArrDelay','Date','DepTime']]\ndf_airport = df_airport[['Origin','DepDelay','Dest','DepTime','ArrDelay','Date_bin','Month','DayofMonth','dep_hour_int']]\n\n#create column with boolean delay occurence value\ndef label4 (row): \n    if row <= 0: return 0\n    if row > 0: return 1\nplane_delay['DepDelay']=plane_delay['DepDelay'].apply(label4) #apply condition\nplane_delay['ArrDelay']=plane_delay['ArrDelay'].apply(label4) #apply condition\ndf_airport['DepDelay']=df_airport['DepDelay'].apply(label4) #apply condition\ndf_airport['ArrDelay']=df_airport['ArrDelay'].apply(label4) #apply condition\n\nplane_delay #explore df, we use df_airport later.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plane_delay['TailNum'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#detect cascading failures\nplane_delay_N485HA = plane_delay_N485HA[['TailNum','DepDelay','ArrDelay']] #columns to use\n\n#count consecutive delays\n\n#departure casc. failure: departure delay in A + arrival delay in B + departure delay on next flight C\nplane_delay_N485HA['dep_casc']=plane_delay_N485HA['DepDelay']+plane_delay_N485HA['ArrDelay']+plane_delay_N485HA['DepDelay'].shift(1)\n\n#departure casc. failure: arrival delay in A + departure delay in B + arrival delay on next flight C\nplane_delay_N485HA['arr_casc']=plane_delay_N485HA['ArrDelay']+plane_delay_N485HA['DepDelay']+plane_delay_N485HA['ArrDelay'].shift(1)\n\n#when a cascading delay has occured, dep_casc or arr_casc is = 3\nplane_delay_N485HA2 = plane_delay_N485HA[(plane_delay_N485HA[\"dep_casc\"] == 3.0) | (plane_delay_N485HA[\"arr_casc\"] == 3.0)]\n\n#count occurences\nplane_delay_N485HA2 =plane_delay_N485HA2.groupby(\"TailNum\").count().reset_index(drop=False)\nplane_delay_N485HA2 = plane_delay_N485HA2[['TailNum','arr_casc']] #sort\nplane_delay_N485HA2.rename(columns={'arr_casc': 'Cascading Failures'}, inplace=True) #rename\nplane_delay_N485HA2 #explore","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#add a second plane to the table\n\n#create df with N477HA flight\nplane_delay_N477HA = plane_delay.loc[plane_delay['TailNum'] == 'N477HA'].sort_values(by=['Date'])\nplane_delay_N477HA = plane_delay_N477HA[['TailNum','DepDelay','ArrDelay']]\nplane_delay_N477HA['dep_casc']=plane_delay_N477HA['DepDelay']+plane_delay_N477HA['ArrDelay']+plane_delay_N477HA['DepDelay'].shift(1)\nplane_delay_N477HA['arr_casc']=plane_delay_N477HA['ArrDelay']+plane_delay_N477HA['DepDelay']+plane_delay_N477HA['ArrDelay'].shift(1)\n\n#df for table\nplane_delay_N477HA2 = plane_delay_N477HA[(plane_delay_N477HA[\"dep_casc\"] == 3.0) | (plane_delay_N477HA[\"arr_casc\"] == 3.0)]\nplane_delay_N477HA2=plane_delay_N477HA2.groupby(\"TailNum\").count().reset_index(drop=False)\nplane_delay_N477HA2 = plane_delay_N477HA2[['TailNum','arr_casc']]\nplane_delay_N477HA2.rename(columns={'arr_casc': 'Cascading Failures'}, inplace=True)\n\ntwo_tails = pd.concat([plane_delay_N485HA2, plane_delay_N477HA2])\ntwo_tails=two_tails.reset_index(drop=True)\ntwo_tails","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#count departure and arrival delays\nprint(plane_delay_N477HA['DepDelay'][(plane_delay_N477HA[\"DepDelay\"] == 1)].count())\nprint(plane_delay_N477HA['DepDelay'][(plane_delay_N477HA[\"DepDelay\"] == 1) & (plane_delay_N477HA[\"ArrDelay\"] == 1)].count())\n\n#count departure and arrival delays\nprint(plane_delay_N485HA['DepDelay'][(plane_delay_N485HA[\"DepDelay\"] == 1)].count())\nprint(plane_delay_N485HA['DepDelay'][(plane_delay_N485HA[\"DepDelay\"] == 1) & (plane_delay_N485HA[\"ArrDelay\"] == 1)].count())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#cascading fail / tailnum with initial delay and delay in A and B airports.\nN477 = (487/805)*100\nN477_B =(487/687)*100\nN477_tot =(487/7696)*100\n\nN485 = (564/937)*100\nN485_b =(564/788)*100 \nN485_tot =(564/7893)*100\n\nprint(\"N477HA with delay in airport A has:\", N477, \"% cascading delay failures\")\nprint(\"N477HA with delay in airport A and B has:\", N477_B , \"% cascading delay failures\")\nprint(\"N477HA has a cascading delay in totl:\", N477_tot , \"% of flights\")\n\n\nprint(\"N485HA with delay in airport A has:\", N485, \"% cascading delay failures\")\nprint(\"N485HA with delay in airport A and B has:\", N485_b, \"% cascading delay failures\")\nprint(\"N477HA has a cascading delay in totl:\", N485_tot , \"% of flights\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create table with all stats\nN485HA_1 = [7893]\nN485HA_col = ['N485HA','Flights']\nN485HA_df = pd.DataFrame(list(zip(N485HA_col,N485HA_1)), columns=[1,2]).explode(2).reset_index(drop=True)\nN485HA_df.rename(columns={1:'TailNum' ,2: 'Flights'}, inplace=True)\n\nN477HA_1 = [7696]\nN477HA_col = ['N477HA','Flights']\nN477HA_df = pd.DataFrame(list(zip(N477HA_col,N477HA_1)), columns=[1,2]).explode(2).reset_index(drop=True)\nN477HA_df.rename(columns={1:'TailNum' ,2: 'Flights'}, inplace=True)\n\ntwo_tails_2 = pd.concat([N485HA_df, N477HA_df],ignore_index=True)\n\ntwo_tails_3 = pd.merge(two_tails, two_tails_2,  how='inner', left_on=['TailNum'], right_on = ['TailNum'])\n\ntwo_tails_3['Casc. Failure (%)'] = two_tails_3['Cascading Failures']/two_tails_3['Flights']*100\ntwo_tails_3 = two_tails_3[['TailNum','Flights','Cascading Failures','Casc. Failure (%)']]\n\n#export cell (dataframe_image library)\ntwo_tails_style2 = two_tails_3.style.background_gradient()\ndfi.export(two_tails_style2,\"Q4_table1.png\")\ntwo_tails_style2","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#explore the df we created for airports earlier\ndf_airport","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create a time bin column\n#choose 3 hours because the flight of interest LAS-LAX is approx. 1h15m, so with delays \n#and a windows to see the potential effects, hence a 3 hour bin seems reasonable.\ndef label5 (row): \n    if row >= 0 and row <=3: return '00-03'\n    if row > 3 and row <=6: return '03-06'\n    if row > 6 and row <=9: return '06-09'\n    if row > 9 and row <=12: return '09-12'\n    if row > 12 and row <=15: return '12-15'\n    if row > 15 and row <=18: return '15-18'\n    if row > 18 and row <=21: return '18-21'\n    if row > 21 and row <=24: return '21-24'\n\ndf_airport['time_range_3hour']=df_airport['dep_hour_int'].apply(label5) #apply condition\ndf_airport","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#select two big airports (LAS VEGAS AND LOS ANGELES)\n\n#Las Vegas\ndf_LAS = df_airport.loc[(df_airport['Origin'] == 'LAS') & (df_airport['Dest'] == 'LAX')] #only the two\ndf_LAS = df_LAS[['Origin','DepDelay','Dest','DepTime',\n                 'ArrDelay','Date_bin','Month','DayofMonth',\n                 'dep_hour_int','time_range_3hour']] #select columns\ndf_LAS = df_LAS.sort_values('Date_bin') #sort\n#add one hour to see how the flight affect following delays in B (dep) and C (arr)\n#becauase the flight is approx. 1.15m\ndf_LAS['Date_bin'] = df_LAS['Date_bin']+timedelta(hours=1) #add one hour to all\n#delay in airport A\ndf_LAS_tot = df_LAS[(df_LAS[\"ArrDelay\"] == 1)]\ndf_LAS_tot = df_LAS_tot.groupby('Date_bin').count() #the bin with +1H grouped \ndf_LAS_tot = df_LAS_tot.reset_index(drop=False)\ndf_LAS_tot = df_LAS_tot[['Date_bin','DepDelay']]\n#rename DepDelay to delay because all counts are where arrdelay is == 1.\ndf_LAS_tot.rename(columns={'DepDelay':'Delay'}, inplace=True) \n\n#Los Angeles\ndf_LAX = df_airport.loc[(df_airport['Origin'] == 'LAX') & (df_airport['Dest'] == 'LAS')] #only the two\ndf_LAX = df_LAX[['Origin','DepDelay','Dest','DepTime',\n                 'ArrDelay','Date_bin','Month','DayofMonth',\n                 'dep_hour_int','time_range_3hour']] #columns for LA\ndf_LAX = df_LAX.sort_values('Date_bin') #sort\n#delay for airport B AND C\ndf_LAX_tot = df_LAX[(df_LAX[\"DepDelay\"] == 1) & (df_LAX[\"ArrDelay\"] == 1)] \ndf_LAX_tot = df_LAX_tot.groupby('Date_bin').count() #group and count\ndf_LAX_tot = df_LAX_tot.reset_index(drop=False)\ndf_LAX_tot = df_LAX_tot[['Date_bin','DepDelay']] #we dont't need all colums because we only have datapoints where both DepDelay and ArrDelay are true.\ndf_LAX_tot.rename(columns={'DepDelay':'Delay'}, inplace=True) #rename, delay = both dep and arrdeay has occured.\n\n#merge on the datebin that is matched to reflect cascading failures\nlas_lax_ABA = pd.merge(df_LAX_tot, df_LAS_tot, on='Date_bin')\n\n#only select where Delay_x(delay in both airport B&C) is equal or more than Delay_y(delay in airport A): \n#otherwise we are just counting the no. of delays in airport A for the particular dataset.\nlas_lax_ABA = las_lax_ABA[(las_lax_ABA[\"Delay_x\"] >= las_lax_ABA[\"Delay_y\"])] #condition on B&C\nlas_lax_ABA_sum = las_lax_ABA[\"Delay_y\"].sum()\nprint(\"sum Delay_y :\", las_lax_ABA[\"Delay_y\"].sum())\nlas_lax_ABA","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create table with dummy vaiables\nchart_df = df_LAX.reset_index(drop=True).merge(df_LAS.reset_index(drop=True), left_index=True, right_index=True)\nprint(\"total flights on route: \",chart_df.shape[0])\n\n#use dummy columns and create a table with cascading delays failures detected\nlas_lax_chart = chart_df[['Origin_y','Origin_x','Dest_x']] #dumme variable\nlas_lax_chart.rename(columns={'Origin_y': 'Airport A','Origin_x':'Airport B','Dest_x':\n                              'Airport C'}, inplace=True) #rename\nlas_lax_chart['Cascading failures']=3685 #casc. detected\nlas_lax_chart=las_lax_chart.head(1)\nlas_lax_chart['Flights'] = 26033 #total flights\nlas_lax_chart['Casc. Failure (%)'] = las_lax_chart['Cascading failures']/las_lax_chart['Flights']*100\nlas_lax_chart_style = las_lax_chart[['Airport A' ,'Airport B','Airport C','Flights',\n                                     'Cascading failures','Casc. Failure (%)']] #columns\nlas_lax_chart_style = las_lax_chart_style.style.background_gradient() #style\ndfi.export(las_lax_chart_style,\"Q4_table2.png\") #export\nlas_lax_chart_style #explore","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create table with dummy vaiables\nchart_df2 = df_LAX_all.reset_index(drop=True).merge(df_LAS.reset_index(drop=True), left_index=True, right_index=True)\nprint(\"total flights on route: \",df_LAX_all.shape[0]) #get total flights no.\n\n#use dummy columns and create a table with cascading delays failures detected\nlas_all_chart = chart_df[['Origin_y','Origin_x','Dest_x']] #dumme variable\nlas_all_chart.rename(columns={'Origin_y': 'Airport A','Origin_x':'Airport B','Dest_x':\n                              'Airport C'}, inplace=True) #rename\nlas_all_chart['Cascading failures']=12903 #casc. detected\nlas_all_chart=las_all_chart.head(1)\nlas_all_chart['Flights'] = 455728 #total flights from LAX\nlas_all_chart['Casc. Failure (%)'] = las_all_chart['Cascading failures']/las_all_chart['Flights']*100\nlas_all_chart = las_all_chart[['Airport A' ,'Airport B','Airport C','Flights',\n                                     'Cascading failures','Casc. Failure (%)']] #columns\n#set rowname in Airport C\n#def label6 (row):\n #  if row['Airport C'] != 'Lego City Airport':\n  #    return 'All other airports'\n#las_all_chart['Airport C']=las_all_chart.apply(lambda row: label6(row), axis=1)\nlas_all_chart['Airport C']='All other airports' #function is not neccesary.\n\n#table style\nlas_all_chart_style = las_all_chart.style.background_gradient() #style\ndfi.export(las_all_chart_style,\"Q4_table3.png\") #export\nlas_all_chart_style #explore","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#merge the df's\nairplane_ml =df_LAX_all.reset_index(drop=True).merge(df_LAS.reset_index(drop=True), left_index=True, right_index=True)\nairplane_ml = airplane_ml[['Origin_x','Dest_x','DepDelay_x','ArrDelay_x','Month_x','DayofMonth_x','dep_hour_int_x','Origin_y','Dest_y','DepDelay_y','ArrDelay_y','Month_y','DayofMonth_y','dep_hour_int_y']]\nairplane_ml['Month_x'] = airplane_ml['Month_x'].map({'January':1,'February':2,'March':3,'April':4,'May':5,'June':6,'July':7,'August':8,'September':9,'October':10,'November':11,'December':12})\nairplane_ml['Month_y'] = airplane_ml['Month_y'].map({'January':1,'February':2,'March':3,'April':4,'May':5,'June':6,'July':7,'August':8,'September':9,'October':10,'November':11,'December':12})\nairplane_ml","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#correlation heatmap\nairplane_ml_heatm = sns.heatmap(airplane_ml.corr()) #plot the heatmap\nairplane_ml_heatm\nairplane_ml_heatm.figure.savefig(\"Q4_plot2.png\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"airplane_ml = pd.get_dummies(airplane_ml, columns=['Origin_x', 'Dest_x','Origin_y', 'Dest_y'])\n\n#split into training and test set(80/20)\nfrom sklearn.model_selection import train_test_split #import train_test_split function\nX_train_cas, X_test_cas, y_train_cas, y_test_cas = train_test_split(airplane_ml.drop('ArrDelay_y', axis=1), airplane_ml['ArrDelay_y'], test_size=0.2, random_state=42)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import librarys and classifier\nfrom sklearn.metrics import precision_score, roc_auc_score, recall_score, accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\n\n#create model\nmodel_cas = RandomForestClassifier(random_state=42)#42: ultimate question of life, the universe, and everything\nmodel_cas.fit(X_train_cas, y_train_cas)\n\n#probability and predictions\nprob_cas = model_cas.predict_proba(X_test_cas)\ntrain_pred_cas = model_cas.predict(X_train_cas)\npred_cas = model_cas.predict(X_test_cas)\n\n#print scores:\nprint('Prediction: {:.5f}'.format(model_cas.score(X_test_cas, y_test_cas)))\nprint('Accuracy: {:.5f}'.format(accuracy_score(y_test_cas, pred_cas)))\nprint('Precision: {:.5f}'.format(precision_score(y_train_cas, train_pred_cas)))\nprint('Recall: {:.5f}'.format(recall_score(y_test_cas, pred_cas)))\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot \nfrom sklearn import metrics\n\ny_pred_proba = model_cas.predict_proba(X_test_cas)[::,1]\nfpr, tpr, _ = metrics.roc_curve(y_test_cas,  y_pred_proba)\nauc = metrics.roc_auc_score(y_test_cas, y_pred_proba)\n\nf, ax = plt.subplots(figsize=(10, 7))\nplt.plot(fpr,tpr,label=\"AUC score:\"+str(auc), alpha=0.8,linewidth=3)\nplt.legend(loc=4, fontsize =15)\nax.set_title('Model that predicts cascading delay failures', fontsize=20, fontname=\"Monospace\", alpha=.8)\nplt.tight_layout(rect=[0, 0, 1, 1]) #tight layout#tight layout\nplt.savefig('Q4_plot1.png', bbox_inches='tight')\nplt.show() #plot","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ml1 = pd.read_csv(\"2006.csv\")\nml2 = pd.read_csv(\"2007.csv\")\n#ml3 = pd.read_csv(\"2008.csv\") #ignore data due to missing months\n\n#if a flight is cancelled, then delay entry shouldn't be possible\nml1=ml1[ml1['Cancelled']==0] #select only not cancelled flights for 2007.\nml2=ml2[ml2['Cancelled']==0] #select only not cancelled flights for 2008.\nml1=ml1[ml1['Diverted']==0] #select only not diverted flights for 2007.\nml2=ml2[ml2['Diverted']==0] #select only not diverted flights for 2008.\n\nprint(ml1.shape)\nprint(ml2.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#take sample to match datapoints (avoid bias)\nml2 = ml2.sample(7019988)\nprint(ml2.shape)\n#combine data\nml = pd.concat([ml1, ml2],ignore_index=True) #combine dataframes\n#create a total delay column\nml['delay_total']= (ml['ArrDelay']+ml['DepDelay'])\n#change timeformat of the 'CRSDepTime' column\nml['CRSDepTime']=(ml['CRSDepTime']/100)\nml['CRSArrTime']=(ml['CRSArrTime']/100)\n#create delay column with multiclass values.\ndelay =[]\nfor row in ml['delay_total']:\n    if row > 45:\n        delay.append(2)    #more than 45 min late (total delay)\n    elif row < 45:  \n        delay.append(1)    #less than 45 min late (total delay)\n    else:\n        delay.append(0)    #ontime or arriving before time (total delay)\nml['delay'] = delay \n\nml #explore data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#no. of total delays above 45 min(2), delays below 45 min (1), and on time or arriving before (0)\nml.value_counts('delay')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#slect relevant columns & check for NA's\nml = ml[['Month','DayOfWeek','DayofMonth','Origin','Dest','CRSDepTime','DepDelay','CRSArrTime','ArrDelay','CarrierDelay','WeatherDelay','NASDelay','SecurityDelay','LateAircraftDelay','delay']]\nml.isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#correlation heatmap\nimport seaborn as sns #imports the seaborn library\nsns.heatmap(ml.corr()) #plot the heatmap","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#take a sample of the data (due to computational limitations)\nml=ml.sample(250000)\n\n#dummies from orgigin and dest columns\nml = pd.get_dummies(ml, columns=['Origin', 'Dest'])\nml.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#split into training and test set(80/20)\nfrom sklearn.model_selection import train_test_split #import  function\nX_train, X_test, y_train, y_test = train_test_split(ml.drop('delay', axis=1), ml['delay'], test_size=0.2, random_state=42)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 1: Gradient Boosting Classifier","metadata":{}},{"cell_type":"code","source":"#import librarys and classifier\nfrom sklearn.metrics import precision_score, roc_auc_score, recall_score, accuracy_score\nfrom sklearn.ensemble import GradientBoostingClassifier\n\n#create model\nmodel1 = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n     max_depth=1, random_state=0).fit(X_train, y_train)\n\n#probability and predictions\nprob1 = model1.predict_proba(X_test)\ntrain_pred1 = model1.predict(X_train)\npred1 = model1.predict(X_test)\n\n#print scores:\nprint('Prediction: {:.5f}'.format(model1.score(X_test, y_test)))\nprint('Accuracy: {:.5f}'.format(accuracy_score(y_test, pred1)))\nprint('AUC score: {:.5f}'.format(roc_auc_score(y_test, prob1, multi_class='ovr')))\nprint('Precision: {:.5f}'.format(precision_score(y_train, train_pred1, average='micro')))\nprint('Recall: {:.5f}'.format(recall_score(y_test, pred1, average='micro')))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 2: Random Forest Classifier","metadata":{}},{"cell_type":"code","source":"#import classifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n#create model\nmodel2 = RandomForestClassifier(random_state=42)#42: ultimate question of life, the universe, and everything\nmodel2.fit(X_train, y_train)\n\n#probability and predictions\nprob2 = model2.predict_proba(X_test)\ntrain_pred2 = model2.predict(X_train)\npred2 = model2.predict(X_test)\n\n#print scores:\nprint('Prediction: {:.5f}'.format(model2.score(X_test, y_test)))\nprint('Accuracy: {:.5f}'.format(accuracy_score(y_test, pred2)))\nprint('AUC score: {:.5f}'.format(roc_auc_score(y_test, prob2, multi_class='ovr')))\nprint('Precision: {:.5f}'.format(precision_score(y_train, train_pred2, average='micro')))\nprint('Recall: {:.5f}'.format(recall_score(y_test, pred2, average='micro')))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 3: Decision Tree Classifier","metadata":{}},{"cell_type":"code","source":"#import classifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n#create model\nmodel3 = DecisionTreeClassifier(random_state=42)\nmodel3.fit(X_train, y_train)\n\n#probability and predictions\nprob3 = model3.predict_proba(X_test)\ntrain_pred3 = model3.predict(X_train)\npred3 = model3.predict(X_test)\n\n#print scores:\nprint('Prediction: {:.5f}'.format(model3.score(X_test, y_test)))\nprint('Accuracy: {:.5f}'.format(accuracy_score(y_test, pred3)))\nprint('AUC score: {:.5f}'.format(roc_auc_score(y_test, prob3, multi_class='ovr')))\nprint('Precision: {:.5f}'.format(precision_score(y_train, train_pred3, average='micro')))\nprint('Recall: {:.5f}'.format(recall_score(y_test, pred3, average='micro')))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###  Random Forest.","metadata":{}},{"cell_type":"code","source":"df_bin = pd.concat([df1, df2],ignore_index=True) #combine dataframes","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_bin['delay_total']= (df_bin['ArrDelay']+df_bin['DepDelay'])\ndf_bin['CRSDepTime']=(df_bin['CRSDepTime']/100)\ndf_bin['CRSArrTime']=(df_bin['CRSArrTime']/100)\n#binary delay column.\ndelay_bin =[]\nfor row in df_bin['delay_total']:\n    if row > 0:\n        delay_bin.append(1)    #delayed (total delay)\n    else:\n        delay_bin.append(0)    #on time or arriving before time (total delay)\ndf_bin['delay'] = delay_bin","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_bin = df_bin[['Month','DayOfWeek','DayofMonth','Origin','Dest','CRSDepTime',\n                 'DepDelay','CRSArrTime','ArrDelay','CarrierDelay','WeatherDelay',\n                 'NASDelay','SecurityDelay','LateAircraftDelay','delay']] #select cols\ndf_bin = df_bin.replace(np.nan, 0) #replace nan with 0 (hence no flight)\ndf_bin=df_bin.sample(250000) #sample\ndf_bin_ml = pd.get_dummies(df_bin, columns=['Origin', 'Dest']) #dummy \ndf_bin_ml.head() #explore","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test/train split\nfrom sklearn.model_selection import train_test_split #import train_test_split function\nX_train_BIN, X_test_BIN, y_train_BIN, y_test_BIN = train_test_split(df_bin_ml.drop('delay', axis=1), df_bin_ml['delay'], test_size=0.2, random_state=42)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import librarys and classifier\nfrom sklearn.metrics import precision_score, roc_auc_score, recall_score, accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\n\n#create model\nmodel4 = RandomForestClassifier(random_state=42)#42: ultimate question of life, the universe, and everything\nmodel4.fit(X_train_BIN, y_train_BIN)\n\n#probability and predictions\nprob_BIN = model4.predict_proba(X_test_BIN)\ntrain_pred_BIN = model4.predict(X_train_BIN)\npred_BIN = model4.predict(X_test_BIN)\n\n#print scores:\nprint('Prediction: {:.5f}'.format(model4.score(X_test_BIN, y_test_BIN)))\nprint('Accuracy: {:.5f}'.format(accuracy_score(y_test_BIN, pred_BIN)))\nprint('Precision: {:.5f}'.format(precision_score(y_train_BIN, train_pred_BIN)))\nprint('Recall: {:.5f}'.format(recall_score(y_test_BIN, pred_BIN)))\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the colour palette\nsns.reset_orig()\nmy_palette = sns.color_palette(\"colorblind\")\nplt.style.use('seaborn-colorblind')\nsns.set_style(\"whitegrid\")\n\n\n#plot \nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ny_pred_proba = model4.predict_proba(X_test_BIN)[::,1]\nfpr, tpr, _ = metrics.roc_curve(y_test_BIN,  y_pred_proba)\nauc = metrics.roc_auc_score(y_test_BIN, y_pred_proba)\n\nf, ax = plt.subplots(figsize=(10, 7))\nplt.plot(fpr,tpr,label=\"AUC score:\"+str(auc))\nplt.legend(loc=4,fontsize = 15)\nax.set_title('Binary Random Forrest model',fontsize=20, fontname=\"Monospace\", alpha=.8)\nplt.tight_layout(rect=[0, 0, 1, 1]) #tight layout\nplt.savefig('Q5_plot2.png', bbox_inches='tight')\nplt.show() #plot\n","metadata":{},"execution_count":null,"outputs":[]}]}